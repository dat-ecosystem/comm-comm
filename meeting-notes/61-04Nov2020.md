# Dat Ecosystem Community Communication

04 Nov 2020

## People

- Martin Heidegger (@martinheidegger)
- Gene Vayngrib (@genevayngrib on Discord) - ok to record
- Mauve (@rangermauve)
- Jiang
- FabianGtz
- Nina Breznik
- Kyran (@KyGost)
- Alex

## Link to the Discord https://discord.gg/JqhC3Hkq

## Introductions

- Gene is from [tradle](https://github.com/tradle), we work on digital identity and personal data custodianship. Initial motivation for exploring hypercore was to solve cloud data residency problem. 
- Fabian is from Mexico and designer and archeologist and I am having interest in the dat protocol and this may be an alternative to the internet.
- Jiang engineer in bejing and I am working on cloud-stuff and also working on a decentralized tool by myself.
- Mauve is an consultant and engineer on various decentralized efforts.
- Nina is living in UK, working on datDot hard on the next release.
- Kyran is living in Australia, working on Agregore(/dat fetch) with Mauve.
- Serapath: working with Nina on a distributed hosting system

## URL's for hyperbees

Mauve: Question: Want to add hyperbee to agregore browser and is wondering if the URL 

Gene: Empathizes the important of good, strong links and may additional information, specifically for.

Jiang: I am working a lot with s3 and a lot of the data/information is added in the querystring. And maybe it could be a little in http style and trying to use querystring to set the version of the file system.

Mauve: I am in agreement about the http things, and I have been working on dat-fetch to get data out and put data in. If I want to get the version of a file I use the ETAG http header and try to implement the parts in there. In dat-fetch there is support for directory listing, if you use URL it will render and with http headers you can use JSON to get json data.

Jiang: Pagination is also pretty useful sometimes and fs/filesystem API don't have this kind of pagination api, parameter in the querystring. I am building a blogging tool and and ordering might be good for this usecase as well.

Mauve: It would be nice to have an issue on dat-fetch to work but I like pagination and sorting on it as well.

https://github.com/RangerMauve/dat-fetch

## Interoperability and URL's

[The discussion](https://github.com/datproject/comm-comm/issues/134) on interoperability has being going on for a while.

serapath: So a hypercore/hyperdrive have more than one feed and a hyperdrive has two and a hosting service needs to get all the related feeds of a hyperdrive. This makes it harder to interact and a standard-ized way of dealing with it would be nice.

mauve: every hyper-data-structure has a header and every data-structure has a header and that specifies and we decided to go with having a string to start and since its protobufs we may be able to extend it down the line. But as serapath mentions earlier and I was hoping to use it in dat-fetch and trying to identify the data.

serapath: The idea on the related-feeds proposal is that there could be a manifest-feed address where all the related feeds are listed. And if a data-structure doesn't have a manifest feed you would need to do that differently. Any future data-structure could work on this. One important discussion is that this would slow down the workflow, but this could be a fallback.

gene: I have been working with my team on working with hyperbee and going to multi-hyperbee and which has multiple feeds, and wonder how to do that the best way.

serapath: With a generalized process we have the possibility to host _any_ hyper based project that should work for any of your datastructures.

jiang: Trying to mention here that you should reference the public key and not the discovery as that will not allow to get the right link:

mauve: +1
# Dat Comm-comm 2020-11-05

## Participants

- Martin Heidegger (@martinheidegger)
- Gene Vayngrib (@genevayngrib on Discord) - ok to record
- Mauve (@rangermauve)
- Jiang
- FabianGtz
- Nina Breznik
- Kyran (@KyGost)
- Alex

## Link to the Discord https://discord.gg/JqhC3Hkq

## Introductions

- Gene is from [tradle](https://github.com/tradle), we work on digital identity and personal data custodianship. Initial motivation for exploring hypercore was to solve cloud data residency problem. 
- Fabian is from Mexico and designer and archeologist and I am having interest in the dat protocol and this may be an alternative to the internet.
- Jiang engineer in bejing and I am working on cloud-stuff and also working on a decentralized tool by myself.
- Mauve is an consultant and engineer on various decentralized efforts.
- Nina is living in UK, working on datDot hard on the next release.
- Kyran is living in Australia, working on Agregore(/dat fetch) with Mauve.
- Serapath: working with Nina on a distributed hosting system

## URL's for hyperbees

Mauve: Question: Want to add hyperbee to agregore browser and is wondering if the URL 

Gene: Empathizes the important of good, strong links and may additional information, specifically for.

Jiang: I am working a lot with s3 and a lot of the data/information is added in the querystring. And maybe it could be a little in http style and trying to use querystring to set the version of the file system.

Mauve: I am in agreement about the http things, and I have been working on dat-fetch to get data out and put data in. If I want to get the version of a file I use the ETAG http header and try to implement the parts in there. In dat-fetch there is support for directory listing, if you use URL it will render and with http headers you can use JSON to get json data.

Jiang: Pagination is also pretty useful sometimes and fs/filesystem API don't have this kind of pagination api, parameter in the querystring. I am building a blogging tool and and ordering might be good for this usecase as well.

Mauve: It would be nice to have an issue on dat-fetch to work but I like pagination and sorting on it as well.

https://github.com/RangerMauve/dat-fetch

## Interoperability and URL's

[The discussion](https://github.com/datproject/comm-comm/issues/134) on interoperability has being going on for a while.

serapath: So a hypercore/hyperdrive have more than one feed and a hyperdrive has two and a hosting service needs to get all the related feeds of a hyperdrive. This makes it harder to interact and a standard-ized way of dealing with it would be nice.

mauve: every hyper-data-structure has a header and every data-structure has a header and that specifies and we decided to go with having a string to start and since its protobufs we may be able to extend it down the line. But as serapath mentions earlier and I was hoping to use it in dat-fetch and trying to identify the data.

serapath: The idea on the related-feeds proposal is that there could be a manifest-feed address where all the related feeds are listed. And if a data-structure doesn't have a manifest feed you would need to do that differently. Any future data-structure could work on this. One important discussion is that this would slow down the workflow, but this could be a fallback.

gene: I have been working with my team on working with hyperbee and going to multi-hyperbee and which has multiple feeds, and wonder how to do that the best way.

serapath: With a generalized process we have the possibility to host _any_ hyper based project that should work for any of your datastructures.

jiang: Trying to mention here that you should reference the public key and not the discovery as that will not allow to get the right link:

mauve: +1
